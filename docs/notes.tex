\documentclass[summaries.tex]{subfiles}
\begin{document}
\section{Math notes}
\mypar{Taylor series multivariate}
\begin{equation}
  f(\boldsymbol{r}_0+\boldsymbol{a}t) = f(\boldsymbol{r}_0) +  [\boldsymbol{a}
    \cdot \nabla f(\boldsymbol{r})] \Big|_{\boldsymbol{r}=\boldsymbol{r}_0}t 
      + \frac{1}{2!} [\boldsymbol{a} \cdot \nabla][\boldsymbol{a} \cdot
        \nabla]f(\boldsymbol{r}) \Big|_{\boldsymbol{r}=
          \boldsymbol{r}_0} t^2 + \ldots
\end{equation}
\href{https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_theorem}
{{\bf Radon Nikodym derivative}} Derivative between probability distributions.\\
\mypar{Shannon Entropy} \\
Self information of event x $= x$ is defined as $I(x) := -\log P(x)$
$$
H(x) = \EEE{x \sim P}{I(x)} = -\EEE{x \sim P}{\log P(x)}
$$
\mypar{Cramer-Rao lower bound} \cite{math-stat16} 
Suppose $\theta$ is an unknown deterministic parameter which is to be estimated from
measurements $x$, distributed according to some pdf $f(x; \theta)$. The variance of any 
\textit{unbiased estimator} $\hat{\theta}$ of $\theta$ is then bounded by reciprocal of
Fischer Information $I(\theta)$:
\begin{align}
  \text{var}(\hat{\theta}) &\geq \frac{1}{I(\theta)} \text{ where }\nonumber\\
  I(\theta) &= \EE{\Big(\frac{\partial l(x; \theta)}{\partial \theta}\Big)^2} \nonumber\\
       &= -\EE{\frac{\partial^2 l(x; \theta)}{\partial \theta^2}} \nonumber
\end{align}
{\bf Note}: See Wikipedia for other more general versions

\mypar{Lipschitz continuity, smoothness, etc.}
$f$ is $M-$\emph{Lipschitz continuous} given M if 
$$|f(x) - f(y)| \leq M|x-y| \forall x,y \in \realline$$. 
If $f$ is differentiable, Lipschitz continuity
says that $f$ has bounded derivative. 

$f$ is $L$-\emph{Lipschitz smooth} if its derivatives are Lipschitz continuous
with $L$. This is called smoothness type $C^{1,1}$ i.e 
$$\forall x, y \in \realline, ||\grad f(x) - \grad f(y)|| \leq L||x-y||$$
The definition does not assume convexity of $f$. Some other equivalent conditions
are: \href{https://xingyuzhou.org/blog/notes/Lipschitz-gradient}{on here}.
\begin{align}
  g(x) = \frac{L}{2}x^\intercal x - f(x) \text{ is convex} \\
  f(y) \leq f(x) + \grad f(x)^\intercal (y-x) + \frac{L}{2}||y-x||^2, \forall x,y 
    \label{eqn:quad_upper}\\
  (\grad f(x) - \grad f(y))^\intercal (x-y) \leq L||x-y||^2, \forall x,y \\
  f(\alpha x + (1 - \alpha)y) \geq \alpha f(x) + (1 - \alpha)f(y) - 
                                \frac{\alpha(1 - \alpha)L}{2}||x-y||^2 
                                \forall x,y \in \realline, \alpha \in [0, 1]\\
  \cdots
\end{align}

\emph{Strong Convextiy}: $f$ is $\alpha$-strongly convex if 
$$\grad^2f(x) \succeq \alpha I \forall x$$
Also
\begin{equation} \label{eqn:conv}
  f(x + y) \geq f(x) + y^\intercal \grad f(x) + \frac{\alpha}{2}||x-y||^2
\end{equation}
\ref{eqn:conv} is equivalent to saying $g(x) = f(x) - \frac{\alpha}{2}||x||^2$
is convex.. Latter is equivalent to $\grad^2 g \succeq 0 \equiv \grad^2 f \succeq \alpha I$.
\href{https://math.stackexchange.com/questions/673898/lipschitz-smoothness-strong-convexity-and-the-hessian}
{more info here} 

\red{Note:}l- strong convexity can be written as 
\begin{equation}
  \label{eqn:str_cvx}
  f(y) \geq f(x) + \grad f(x)^\intercal (y-x) + \frac{l}{2}||y-x||^2
\end{equation}
Equation \ref{eqn:str_cvx} is direct contrast to \ref{eqn:quad_upper}. 
$\frac{L}{l}$ is called condition number of matrix.

\mypar{Function Space Theory, Functional Analysis and Functional Optimization}
\href{https://pdfs.semanticscholar.org/f4c7/e5f8ce51f19be24c765f2e98481eca71e55f.pdf}
{this} is a good reference on Function spaces (Banach Spaces, Hilbert spaces, etc).

\mypar{Functional Optimization on KL divergence}
\INPROGRESS
In function space, dot product is extended as $\langle \cdot, \cdot \rangle$ 
\begin{align*}
    \langle f, g \rangle &= \int f(\theta) g(\theta) d\theta 
\end{align*}
Now,
\begin{align}
    \kl{q||p} &= \EEE{q}{\log q} - \EEE{q}{\log p} \nonumber\\
              &= \langle q, \log \frac{q}{p} \rangle \label{eqn:kl_dot}\\
              &=: f(q) \nonumber
\end{align}

For functional $f$, derivative defined as
\begin{align}
    f(q + \epsilon d) &= f(q) + f^\prime(q)\epsilon + O(\epsilon^2)\\
          f^\prime(q) &= \int \frac{\partial f(q)}{\partial q(\theta)} d(\theta) d\theta\\
                      &\equiv \langle \grad f(q), d \rangle 
\end{align}
From equation \ref{eqn:kl_dot}, 
\begin{equation}
    \grad f(q) := \frac{\partial f(q)}{\partial q} = \log \frac{q}{p}
\end{equation}
In finite dimensional optimization, we look for candidates for optima by looking for $\bx^\ast$ where
$\grad f(\bx^\ast) = 0$. This is equivalent to asking every component of $\grad f \overset{!}{=} 0$. For
functions we look for $q^\ast$ s.t 

$$\frac{\partial f(q^\ast)}{\partial q (\theta)} \overset{!}{=} 0 \forall x \in \realline$$

\mypar{Frank Wolfe for Variational Inference Optimization}
\INPROGRESS
Algorithm \ref{alg:fw} where optimization is over probability distributions. $q_t, s$ in
\cite{locatello2018boosting} is $\equiv$ $\bx_t, \bs$ in all discussion on Frank-Wolfe. One is a function
while the other is a vector. $\bx_t$ can also be seen as parameters of the probability distributions
but we do not use the same distance functions and gradients Objective function so it would be better to
stay in function space.\\

Objective function $f$ is $f(\bx_t) \equiv f(q_t) = \data^{kl}{q_t || p}$ where $p$ is the target
distribution. $\mathbf{d}_t = \bs_t - \bx_t$ \todo[color=cyan]{is there an analog for this in functional space?}. $||\mathbf{d}_t||$ can be replaced by a divergence metric between $s$ and $q_t$ like 
$\kl{s_t || q_t}$. We can also try $\kl{q_t||s}$ or
\href{https://en.wikipedia.org/wiki/Statistical_distance}{others metrics}. 
Gap $g_t$ is always scalar.
\begin{align}
    g_t &= -\langle \grad f(\bx_t), \mathbf{d}_t \rangle \geq 0 \nonumber\\
        &= \langle \grad f(\bx_t), \bx_t \rangle - \langle \grad f(\bx_t), \bs_t \rangle 
        \label{eqn:gap}
\end{align}
For probability distribution $q$, 
\begin{align}
   \langle h, q \rangle = 
   \langle q, h \rangle &= \EEE{q}{h} \\
                        &\approx \frac{1}{S} \sum_{\theta_{i} \sim q}^{i=1..S} f(\theta_i)
\end{align}

i.e expectation of $f$ under $q$. \ref{eqn:gap} then becomes
\begin{align}
    g_t &= \EEE{q_t}{\grad f(q_t)} - \EEE{s_t}{\grad f(q_t)} \\
        &= \EEE{q_t}{\log \frac{q_t}{p}} - \EEE{s_t}{\log \frac{q_t}{p}}
\end{align}


\newpage
\section{Code Notes}
Normal distribution edward

\begin{minted}{python}
from edward.models import Normal
from keras.layers import Dense

hidden = Dense(256, activation='relu')(x_ph)
qz = Normal(loc=Dense(10)(hidden),
scale=Dense(10, activation='softplus')(hidden))
\end{minted}

\label{code:ed_tf_issue}
\texttt{Edward} has issues with \texttt{Tensorflow versions > 1.7} see
\href{https://github.com/blei-lab/edward/issues/893}{\#893}. Issue is non-trivial
and it doesn't seem like there is a plan to fix since \texttt{Edward2} is
part of \texttt{tensorflow\_probability}.

\section{Web pages}
\begin{enumerate}
  \item \href{http://blog.mrtz.org/2013/09/07/the-zen-of-gradient-descent.html}
{Zen of gradient descent with intro to Nexterov Method}  \\
  \item \href{https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/}
{I am a bandit Nesterov accelerated} 
  \item \href{http://www.stat.cmu.edu/~ryantibs/convexopt-S15/scribes/23-cond-grad-scribed.pdf}
{CMU Stats FW lecture} \label{web:cmu}
\end{enumerate}

\biblio
\end{document}

